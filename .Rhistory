getwd()
install.packages("devtools")
getwd()
devtools::install_github("OmaymaS/yelpr")
source('D:/Projects/R/Toronto Yelp/yelp.R')
library(yelpr)
client_id <-"An9XHmTne2YakvLt57jYtg"
## assign app key
api_key <-"lEau7cqpf9e_850UUf3sHuE0MA8Ay-mlXSOMbXbarxkyVesSPXd1ltyi63iW841T3d0Ak14kAnufxxhTqCvqtls6AzlUnWEFAWHlf6U1Qn_S6BKy_aNWTBvHJmo1W3Yx"
# search businesses with keyword 'chinese' in 'Toronto'
business_ny <- business_search(api_key = key,
location = 'Toronto',
term = "restaurants",
limit = 5)
source('D:/Projects/R/Toronto Yelp/yelp.R', echo=TRUE)
View(business_ny)
View(business_ny)
View(business_ny)
View(business_ny)
business_ny
business_ny <- business_search(api_key = key,
location = 'Toronto',
term = "restaurants",
limit = 50)
View(business_ny)
business_ny
print(class(busines)business_ny)
print(class(business_ny))
business_ny["businesses"]
business_ny$businesses
datalist = list()
dat <-business_ny$businesses
dat$i <-1
datalist[[1]] <-dat
for (i in 2:20) {
business_ny <- business_search(api_key = key,
location = 'Toronto',
term = "restaurants",
limit =50, offset=50*(i-1)+1)
dat <-business_ny$businesses
dat$i <-1
datalist[[i]] <-dat
}
datalist
View(datalist)
View(datalist[[1]])
View(datalist[[2]])
install.packages("mongolite")
datalist
library(plyr)
df<-ldply(datalist, rbind)
df<-as.data.frame(ldply(datalist, rbind))
df<-as.data.frame(ldply(datalist, rbind, output="more"))
df<-as.data.frame(ldply(datalist, rbind, output="more"))
df<-ldply(datalist, rbind)
df<-do.call(rbind, datalist)
df<-do.call("rbind", datalist)
df<-ldply(datlist)[,-1]
df<-ldply(datzlist)[,-1]
df<-ldply(datalist)[,-1]
devtools::install_github("hadley/plyr")
devtools::install_github("hadley/plyr")
devtools::install_github("hadley/plyr")
library('httr')
url <- 'https://www.fidelity.com/fund-screener/evaluator.shtml#!&ft=BAL_all&ntf=N&expand=%24FundType&rsk=5'
page <- GET(url)
Successâ€¦
print(http_status(page))
library('httr')
url <- 'https://www.yelp.com/biz/pai-northern-thai-kitchen-toronto-5?adjust_creative=An9XHmTne2YakvLt57jYtg&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_search&utm_source=An9XHmTne2YakvLt57jYtg'
page <- GET(url)
print(http_status(page))
page_text <- content(page, as='text')
page_text
#Step 1: Fire up Selenium
library('RSelenium')
checkForServer() # search for and download Selenium Server java binary.  Only need to run once.
startServer() # run Selenium Server binary
remDr <- remoteDriver(browserName="firefox", port=4444) # instantiate remote driver to connect to Selenium Server
remDr$open(silent=T) # open web browser
library('wdman')
library('wdman')
remDr=remoteDriver(remoteServerAddr='localhost', port=4444L, browerName='Chrome')
remDr$open(silent=T) # open web browser
remDr=remoteDriver(remoteServerAddr='localhost', port=4444L, browserName='Chrome')
remDr$open(silent=T) # open web browser
remDr$navigate(url)
remDr=remoteDriver(remoteServerAddr='localhost', port=4444, browserName='Chrome')
remDr$open(silent=T) # open web browser
driver<- rsDriver(browser=c("Chrome"))
remDr <- driver[["client"]]
remDr$open()
driver<- rsDriver(browser=c("chrome"))
remDr <- driver[["client"]]
remDr$open()
driver<- rsDriver(browser=c("chrome"))
remDr <- driver[["client"]]
remDr$open()
driver<- rsDriver(browser=c("chrome"))
remDr <- driver[["client"]]
library('wdman')
library('RSelenium')
remDr <- driver[["client"]]
rD <- rsDriver(port=4444L,browser="chrome")
binman::rm_platform("phantomjs")
wdman::selenium(retcommand = TRUE)
driver<- rsDriver(browser=c("chrome"))
remDr <- driver[["client"]]
remDr$navigate(url)
install.packages("XML")
install.packages("XML")
install.packages("XML")
install.packages("XML")
library(XML)
install.packages('XML')
install.packages("XML")
library('XML')
master <- c()
n <- 5 # number of pages to scrape.  80 pages in total.  I just scraped 5 pages for this example.
elem <- remDr$find_elements_by_tag_name("li") # get big table in text string
elem <- remDr$findElement(using="tag name", value='li') # get big table in text string
library('RSelenium')
driver<- rsDriver(browser=c("chrome"))
remDr <- driver[["client"]]
remDr$open()
remDr$navigate(url)
driver<- rsDriver(browser=c("chrome"))
remDr <- driver[["client"]]
remDr$open()
url<-'https://www.yelp.com/biz/pai-northern-thai-kitchen-toronto-5'
remDr$navigate(url)
elem <- remDr$findElement(using="tag name", value='li')
eleme
elem
elem <- remDr$findElement(using="xpath","//*[@id="super-container"]/div/div/div[1]/div[3]/div[1]/div[2]/ul")
elem <- remDr$findElement(using="xpath","//[@id="super-container"]/div/div/div[1]/div[3]/div[1]/div[2]/ul")
elem <- remDr$findElement(using="xpath",'//*[@id="super-container"]/div/div/div[1]/div[3]/div[1]/div[2]/ul')
elem
length(elem)
elem <- remDr$findElement(using='class','list ylist-bordered reviews')
elem <- remDr$findElement(using='class',value='list ylist-bordered reviews')
elem <- remDr$findElement(using='class name',value='list ylist-bordered reviews')
elem <- remDr$findElement(using='class name',value="list ylist-bordered reviews")
elem <- remDr$findElement(using='class name',"list ylist-bordered reviews")
elem <- remDr$findElement(using='class name',".list.ylist-bordered reviews")
elem <- remDr$findElement(using='class name',"reviews")
elem
ul <- elem %>% findElementsFromElement("css", "ul")
install.packages("magrittr")
library('magrittr')
ul <- elem %>% findElementsFromElement("css", "ul")
install.packages("seleniumPipes")
library('seleniumPipes')
ul <- elem %>% findElementsFromElement("css", "ul")
ul <- elem %>% findElementsFromElement("css", "li")
elem <- remDr$findElement(using='class name',"ylist")
driver<- rsDriver(browser=c("chrome"))
remDr <- driver[["client"]]
remDr$open()
url<-'https://www.yelp.com/biz/pai-northern-thai-kitchen-toronto-5'
remDr$navigate(url)
elem <- remDr$findElement(using='class name',"ylist")
ul <- elem %>% findElementsFromElement("css", "li")
elem <- remDr$findElement("css", "ul")
ul <- elem %>% findElementsFromElement("css", "li")
elem
elemtxt <- elem$getElementAttribute("outerHTML")[[1]]
elemtxt
elem <- remDr$findElement(using="id", value="reviews")
elemtxt <- elem$getElementAttribute("outerHTML")[[1]]
elem <- remDr$findElement(using="class name", value="reviews")
elemtxt <- elem$getElementAttribute("outerHTML")[[1]]
elemtxt
elemtxt
elemxml <- htmlTreeParse(elemtxt, useInternalNodes=T) # parse string into HTML tree to allow for querying with XPath
fundList <- unlist(xpathApply(elemxml, '//[@id="super-container"]/div/div/div[1]/div[3]/div[1]/div[2]/ul/li[2]/div/div[1]/div/div/div[1]/div/a', xmlGetAttr, 'href')) # parses out just the fund name and ticker using XPat
//*
fundList <- unlist(xpathApply(elemxml, '//[@id="super-container"]/div/div/div[1]/div[3]/div[1]/div[2]/ul/li[2]/div/div[1]/div/div/div[1]/div/a', xmlGetAttr, 'href')
)
fundList <- unlist(xpathApply(elemxml, '//*[@id="super-container"]/div/div/div[1]/div[3]/div[1]/div[2]/ul/li[2]/div/div[1]/div/div/div[1]/div/a', xmlGetAttr, 'href')) # parses out just the fund name and ticker using XPat
//*
fundList <- unlist(xpathApply(elemxml, '//*[@id="super-container"]/div/div/div[1]/div[3]/div[1]/div[2]/ul/li[2]/div/div[1]/div/div/div[1]/div/a', xmlGetAttr, 'href')) # parses out just the fund name and ticker using XPat
fundList
elem <- remDr$findElements(using="class name", value="js-analytics-click")
driver<- rsDriver(browser=c("chrome"))
remDr <- driver[["client"]]
remDr$open()
url<-'https://www.yelp.com/biz/pai-northern-thai-kitchen-toronto-5'
remDr$navigate(url)
elem <- remDr$findElements(using="class name", value="js-analytics-click")
elem
elemtxt <- elem$getElementAttribute("outerHTML")[[1]]
elems <- remDr$findElements(using="class name", value="js-analytics-click")
elem <- elems[[1]]
class(elem)
elem$getElementAttribute("href")
elem$getElementAttribute("href")[1]
install.packages("Rcurl")
install.packages("RCurl")
library('RCurl')
sParse <- htmlParse(url)
gsite<-getURL(url)
sParse <- htmlParse(url)
sParse <- htmlParse(gsite)
xpathSApply(sParse, "//a[@class='js-analytics-click']", xmlGetAttr, "href")
xpathSApply(sParse, "//a[@data-analytics-label='user-photo']", xmlGetAttr, "href")
xpathSApply(sParse, "//div[@class='i-stars']", xmlGetAttr, "title")
xpathSApply(sParse, "//a[@data-analytics-label='user-photo']", xmlGetAttr, "href")
xpathSApply(sParse, "//div[@class='i-stars']", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='i-stars--regular-5rating-large']", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='i-stars i-stars--regular-5rating-large']", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='i-stars i-stars--regular-5 rating-large']", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='offscreen']", xmlGetAttr, "alt")
xpathSApply(sParse, "//p", xmlGetText, "alt")
xpathSApply(sParse, "//p", xml_text)
xpathSApply(sParse, "//p//text()")
xpathSApply(sParse, "//div[@class='review-content']p//text()")
xpathSApply(sParse, "//div[@class='review-content']/p//text()")
xpathSApply(sParse, "//div[@class='review-content']//text()")
xpathSApply(sParse, "//p[@lang='en']//text()")
xpathSApply(sParse, "//p[@lang='en']",xmlValue)
xpathSApply(sParse, "//span[@class='rating-qualifier']",xmlValue)
xpathSApply(sParse, "//p[@lang='en']",xmlValue)
xpathSApply(sParse, "//a[@data-analytics-label='user-photo']", xmlGetAttr, "href")
xpathSApply(sParse, "//span[@class='rating-qualifier']",xmlValue)
xpathSApply(sParse, "//p[@lang='en']",xmlValue)
xpathSApply(sParse, "//a[@data-analytics-label='user-photo']", xmlGetAttr, "href"
xpathSApply(sParse, "//a[@data-analytics-label='user-photo']", xmlGetAttr, "href")
xpathSApply(sParse, "//a[@data-analytics-label='user-photo']", xmlGetAttr, "href")
xpathSApply(sParse, "//a[@class='user-display-name js-analytics-click']", xmlGetAttr, "href")
xpathSApply(sParse, "//a[@id='dropdown_user-name']", xmlGetAttr, "href")
xpathSApply(sParse, "//div[@class='review-content']//text()")
xpathSApply(sParse, "//span[@class='rating-qualifier']",xmlValue)
xpathSApply(sParse, "//p[@lang='en']",xmlValue)
xpathSApply(sParse, "//div[contains(@class,'atag')]", xmlGetAttr, "title")
xpathSApply(sParse, "//div[contains(@class,'i-stars')]", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='ylist ylist-bordered reviews']/div[contains(@class,''i-stars')]", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='ylist ylist-bordered reviews']/div[contains(@class,'i-stars')]", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='ylist ylist-bordered reviews']", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='ylist ylist-bordered reviews']/div[contains(@class,'i-stars')", xmlGetAttr, "title")
xpathSApply(sParse, "//ul[@class='ylist ylist-bordered reviews']/div[contains(@class,'i-stars')", xmlGetAttr, "title")
xpathSApply(sParse, "//ul[@class='ylist ylist-bordered reviews']/li/div/div/div/div/div[contains(@class,'i-stars')", xmlGetAttr, "title")
xpathSApply(sParse, "//ul[@class='biz-rating biz-rating-large clearfix']/div[contains(@class,'i-stars')", xmlGetAttr, "title")
xpathSApply(sParse, "//ul[@class='biz-rating biz-rating-large clearfix']/div[contains(@class,'i-stars')]", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='biz-rating biz-rating-large clearfix']/div[contains(@class,'i-stars')]", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='review-content']/div/div[contains(@class,'i-stars')]", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='review-content']/div/div/div[contains(@class,'i-stars')]", xmlGetAttr, "title")
xpathSApply(sParse, "//div[@class='review-content']//text()")
xpathSApply(sParse, "//span[@class='rating-qualifier']",xmlValue)
xpathSApply(sParse, "//p[@lang='en']",xmlValue)
xpathSApply(sParse, "//a[@id='dropdown_user-name']", xmlGetAttr, "href")
xpathSApply(sParse, "//span[@class='rating-qualifier']",xmlValue) #DATE
xpathSApply(sParse, "//a[@id='dropdown_user-name']", xmlGetAttr, "href")
xpathSApply(sParse, "//div[@class='review-sidebar-content']/div/div/ul/li/a[@id='dropdown_user-name']", xmlGetAttr, "href")
